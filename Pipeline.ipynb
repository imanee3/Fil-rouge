{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331ce6c9",
   "metadata": {},
   "source": [
    "## Pipeline de Collecte Multi-Sources (API REST & Web Scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4876df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data\\f1_constructor_finance_2021_2025.csv créé (50 lignes)\n",
      "✅ data\\f1_driver_finance_2021_2025.csv créé (110 lignes)\n"
     ]
    }
   ],
   "source": [
    "# scripts/make_finance_csvs_filled_2021_2025.py\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup  # <-- IMPORTANT (pip install beautifulsoup4)\n",
    "\n",
    "SEASONS = [2021, 2022, 2023, 2024, 2025]\n",
    "\n",
    "# Jolpica = Ergast-compatible (Ergast a été arrêté)\n",
    "ERGAST = \"https://api.jolpi.ca/ergast/f1\"\n",
    "\n",
    "OUT_DIR = Path(\"data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COST_CAP_BASELINE_USD = {\n",
    "    2021: 145_000_000,\n",
    "    2022: 140_000_000,\n",
    "    2023: 135_000_000,\n",
    "    2024: 135_000_000,\n",
    "    2025: 135_000_000,\n",
    "}\n",
    "\n",
    "SALARY_SOURCES = {\n",
    "    2021: \"https://racingnews365.com/formula-1-driver-salaries-2021\",\n",
    "    2022: \"https://racingnews365.com/what-are-the-driver-salaries-for-2022\",\n",
    "    2023: \"https://racingnews365.com/f1-driver-salaries-2023\",\n",
    "    2024: \"https://www.nbcnewyork.com/news/sports/how-much-are-f1-drivers-paid-salaries-2024/5192874/\",\n",
    "    2025: \"https://racingnews365.com/2025-f1-driver-salaries-how-much-do-f1-drivers-earn\",\n",
    "}\n",
    "\n",
    "NAME_OVERRIDES = {\n",
    "    2025: {\"bortoletto\": \"bortoleto\"},\n",
    "}\n",
    "\n",
    "# ---------------------- HTTP (ROBUST) ----------------------\n",
    "\n",
    "def get_json(url: str, retries: int = 6, backoff: float = 1.5) -> Dict[str, Any]:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; F1PerformanceArchitect/1.0)\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    last_err: Optional[Exception] = None\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=30, headers=headers)\n",
    "            if r.status_code in (429, 403, 408, 441, 500, 502, 503, 504):\n",
    "                time.sleep(backoff * (i + 1))\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(backoff * (i + 1))\n",
    "    raise last_err if last_err else RuntimeError(f\"Échec requête: {url}\")\n",
    "\n",
    "def get_html(url: str) -> str:\n",
    "    r = requests.get(url, timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "# ---------------------- NORMALIZATION ----------------------\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ---------------------- ERGAST-COMPATIBLE FETCH ----------------------\n",
    "\n",
    "def get_constructor_standings(season: int) -> List[Dict[str, Any]]:\n",
    "    url = f\"{ERGAST}/{season}/constructorStandings.json\"\n",
    "    data = get_json(url)\n",
    "    lists = data[\"MRData\"][\"StandingsTable\"][\"StandingsLists\"]\n",
    "    if not lists:\n",
    "        return []\n",
    "    standings = lists[0][\"ConstructorStandings\"]\n",
    "    out = []\n",
    "    for s in standings:\n",
    "        c = s[\"Constructor\"]\n",
    "        out.append({\n",
    "            \"season\": season,\n",
    "            \"constructorId\": c[\"constructorId\"],\n",
    "            \"constructorName\": c[\"name\"],\n",
    "            \"constructorRank\": int(s[\"position\"]),\n",
    "            \"constructorPoints\": float(s[\"points\"]),\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def get_driver_standings(season: int) -> List[Dict[str, Any]]:\n",
    "    url = f\"{ERGAST}/{season}/driverStandings.json\"\n",
    "    data = get_json(url)\n",
    "    lists = data[\"MRData\"][\"StandingsTable\"][\"StandingsLists\"]\n",
    "    if not lists:\n",
    "        return []\n",
    "    standings = lists[0][\"DriverStandings\"]\n",
    "    out = []\n",
    "    for s in standings:\n",
    "        d = s[\"Driver\"]\n",
    "        constructors = s.get(\"Constructors\", [])\n",
    "        constructor = constructors[0] if constructors else None\n",
    "        out.append({\n",
    "            \"season\": season,\n",
    "            \"driverId\": d[\"driverId\"],\n",
    "            \"givenName\": d[\"givenName\"],\n",
    "            \"familyName\": d[\"familyName\"],\n",
    "            \"driverName\": f'{d[\"givenName\"]} {d[\"familyName\"]}',\n",
    "            \"driverCode\": d.get(\"code\", \"\"),\n",
    "            \"driverNumber\": d.get(\"permanentNumber\", \"\"),\n",
    "            \"driverRank\": int(s[\"position\"]),\n",
    "            \"driverPoints\": float(s[\"points\"]),\n",
    "            \"constructorId\": constructor[\"constructorId\"] if constructor else \"\",\n",
    "            \"constructorName\": constructor[\"name\"] if constructor else \"\",\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def spend_factor_from_rank(rank: int) -> float:\n",
    "    if rank <= 3:\n",
    "        return 0.98\n",
    "    if rank <= 6:\n",
    "        return 0.95\n",
    "    return 0.92\n",
    "\n",
    "# ---------------------- SALARY PARSING (NO LXML) ----------------------\n",
    "\n",
    "def parse_salary_cell_to_millions(value: str) -> Tuple[Optional[float], Optional[float], Optional[float]]:\n",
    "    if value is None:\n",
    "        return (None, None, None)\n",
    "    raw = str(value).strip()\n",
    "    if raw == \"\" or raw.lower() in {\"nan\", \"none\"}:\n",
    "        return (None, None, None)\n",
    "\n",
    "    s = raw.lower().replace(\"$\", \"\").replace(\"million\", \"\").replace(\"m\", \"\").strip()\n",
    "    s = s.replace(\",\", \".\")\n",
    "    m = re.match(r\"^\\s*(\\d+(\\.\\d+)?)\\s*-\\s*(\\d+(\\.\\d+)?)\\s*$\", s)\n",
    "    if m:\n",
    "        a = float(m.group(1))\n",
    "        b = float(m.group(3))\n",
    "        return (a, b, (a + b) / 2.0)\n",
    "\n",
    "    m = re.match(r\"^\\s*(\\d+(\\.\\d+)?)\\s*$\", s)\n",
    "    if m:\n",
    "        a = float(m.group(1))\n",
    "        return (a, a, a)\n",
    "\n",
    "    m = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "    if m:\n",
    "        a = float(m.group(1))\n",
    "        return (a, a, a)\n",
    "\n",
    "    return (None, None, None)\n",
    "\n",
    "def extract_salary_table_bs4(season: int, url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrait un tableau salaires avec BeautifulSoup (pas besoin de lxml).\n",
    "    On cherche le tableau qui contient des en-têtes similaires à Driver/Name + Salary.\n",
    "    \"\"\"\n",
    "    html = get_html(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if not tables:\n",
    "        raise ValueError(f\"Aucun tableau HTML trouvé pour {season} sur {url}\")\n",
    "\n",
    "    def table_score(table) -> int:\n",
    "        th_text = \" \".join([normalize_text(th.get_text(\" \")) for th in table.find_all(\"th\")])\n",
    "        score = 0\n",
    "        if \"driver\" in th_text or \"name\" in th_text:\n",
    "            score += 2\n",
    "        if \"salary\" in th_text or \"earn\" in th_text:\n",
    "            score += 2\n",
    "        if \"team\" in th_text:\n",
    "            score += 1\n",
    "        return score\n",
    "\n",
    "    best = max(tables, key=table_score)\n",
    "\n",
    "    # headers\n",
    "    headers = [h.get_text(\" \", strip=True) for h in best.find_all(\"th\")]\n",
    "    if not headers:\n",
    "        # parfois headers dans première ligne td\n",
    "        first_row = best.find(\"tr\")\n",
    "        headers = [td.get_text(\" \", strip=True) for td in first_row.find_all(\"td\")]\n",
    "\n",
    "    # rows\n",
    "    rows = []\n",
    "    for tr in best.find_all(\"tr\"):\n",
    "        cells = [td.get_text(\" \", strip=True) for td in tr.find_all([\"td\", \"th\"])]\n",
    "        if len(cells) < 2:\n",
    "            continue\n",
    "        rows.append(cells)\n",
    "\n",
    "    # construire DF en mode flexible\n",
    "    df = pd.DataFrame(rows[1:], columns=rows[0]) if len(rows) > 1 else pd.DataFrame()\n",
    "    # détecter colonnes driver / salary\n",
    "    cols_norm = {c: normalize_text(c) for c in df.columns}\n",
    "    driver_col = None\n",
    "    salary_col = None\n",
    "    for c, nc in cols_norm.items():\n",
    "        if driver_col is None and (\"driver\" in nc or \"name\" in nc):\n",
    "            driver_col = c\n",
    "        if salary_col is None and (\"salary\" in nc or \"earn\" in nc):\n",
    "            salary_col = c\n",
    "\n",
    "    if driver_col is None or salary_col is None:\n",
    "        raise ValueError(f\"Colonnes driver/salary introuvables pour {season}. Colonnes: {list(df.columns)}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"season\": season,\n",
    "        \"driver_raw\": df[driver_col],\n",
    "        \"salary_raw\": df[salary_col],\n",
    "        \"source_url\": url\n",
    "    })\n",
    "    return out\n",
    "\n",
    "def build_salary_lookup_by_driverid(season: int, drivers_df: pd.DataFrame, salary_table: pd.DataFrame) -> pd.DataFrame:\n",
    "    drivers_df = drivers_df.copy()\n",
    "    drivers_df[\"family_norm\"] = drivers_df[\"familyName\"].map(normalize_text)\n",
    "    drivers_df[\"given_norm\"] = drivers_df[\"givenName\"].map(normalize_text)\n",
    "    family_to_ids = drivers_df.groupby(\"family_norm\")[\"driverId\"].apply(list).to_dict()\n",
    "\n",
    "    def map_row_to_driverid(name_raw: str) -> str:\n",
    "        if not isinstance(name_raw, str):\n",
    "            return \"\"\n",
    "        n = normalize_text(name_raw)\n",
    "        for wrong, correct in NAME_OVERRIDES.get(season, {}).items():\n",
    "            n = re.sub(rf\"\\b{wrong}\\b\", correct, n)\n",
    "        tokens = n.split()\n",
    "        if not tokens:\n",
    "            return \"\"\n",
    "        family = tokens[-1]\n",
    "        ids = family_to_ids.get(family, [])\n",
    "        if len(ids) == 1:\n",
    "            return ids[0]\n",
    "        if len(tokens) >= 2:\n",
    "            given = tokens[0]\n",
    "            cand = drivers_df[(drivers_df[\"family_norm\"] == family) & (drivers_df[\"given_norm\"] == given)]\n",
    "            if len(cand) == 1:\n",
    "                return cand.iloc[0][\"driverId\"]\n",
    "        return \"\"\n",
    "\n",
    "    out = salary_table.copy()\n",
    "    out[\"driverId\"] = out[\"driver_raw\"].apply(map_row_to_driverid)\n",
    "\n",
    "    mins, maxs, mids = [], [], []\n",
    "    for v in out[\"salary_raw\"].tolist():\n",
    "        mn, mx, md = parse_salary_cell_to_millions(v)\n",
    "        mins.append(mn); maxs.append(mx); mids.append(md)\n",
    "\n",
    "    out[\"salary_million_min\"] = mins\n",
    "    out[\"salary_million_max\"] = maxs\n",
    "    out[\"salary_million_mid\"] = mids\n",
    "    out[\"estimatedSalaryUSD\"] = out[\"salary_million_mid\"].apply(\n",
    "        lambda x: int(round(x * 1_000_000)) if pd.notna(x) and x is not None else \"\"\n",
    "    )\n",
    "    out = out[out[\"driverId\"] != \"\"].copy()\n",
    "    return out[[\"season\", \"driverId\", \"estimatedSalaryUSD\", \"source_url\"]]\n",
    "\n",
    "# ---------------------- CSV BUILDERS ----------------------\n",
    "\n",
    "def build_constructor_finance_csv() -> Path:\n",
    "    rows = []\n",
    "    for season in SEASONS:\n",
    "        cap = COST_CAP_BASELINE_USD.get(season)\n",
    "        standings = get_constructor_standings(season)\n",
    "        for s in standings:\n",
    "            factor = spend_factor_from_rank(s[\"constructorRank\"])\n",
    "            rows.append({\n",
    "                \"season\": season,\n",
    "                \"constructorId\": s[\"constructorId\"],\n",
    "                \"constructorName\": s[\"constructorName\"],\n",
    "                \"constructorRank\": s[\"constructorRank\"],\n",
    "                \"constructorPoints\": s[\"constructorPoints\"],\n",
    "                \"costCapBaselineUSD\": cap,\n",
    "                \"spendFactorProxy\": factor,\n",
    "                \"estimatedSpendUSDProxy\": round(cap * factor) if cap else \"\",\n",
    "                \"note\": \"Budget proxy basé sur Cost Cap + rang constructeur (budgets réels non publics)\",\n",
    "            })\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"season\", \"constructorRank\", \"constructorId\"])\n",
    "    out_path = OUT_DIR / \"f1_constructor_finance_2021_2025.csv\"\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ {out_path} créé ({len(df)} lignes)\")\n",
    "    return out_path\n",
    "\n",
    "def build_driver_finance_filled_csv() -> Path:\n",
    "    all_rows = []\n",
    "    for season in SEASONS:\n",
    "        drivers = pd.DataFrame(get_driver_standings(season))\n",
    "        if drivers.empty:\n",
    "            continue\n",
    "\n",
    "        src_url = SALARY_SOURCES[season]\n",
    "        salary_table = extract_salary_table_bs4(season, src_url)\n",
    "        salary_map = build_salary_lookup_by_driverid(season, drivers, salary_table)\n",
    "\n",
    "        merged = drivers.merge(\n",
    "            salary_map[[\"season\", \"driverId\", \"estimatedSalaryUSD\", \"source_url\"]],\n",
    "            on=[\"season\", \"driverId\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        merged[\"estimatedSalaryUSD\"] = merged[\"estimatedSalaryUSD\"].fillna(\"\")\n",
    "        merged[\"salarySourceURL\"] = merged[\"source_url\"].fillna(\"\")\n",
    "        merged.drop(columns=[\"source_url\"], inplace=True)\n",
    "\n",
    "        merged = merged[[\n",
    "            \"season\", \"driverId\", \"constructorId\",\n",
    "            \"givenName\", \"familyName\", \"driverName\",\n",
    "            \"driverCode\", \"driverNumber\",\n",
    "            \"driverRank\", \"driverPoints\",\n",
    "            \"estimatedSalaryUSD\", \"salarySourceURL\",\n",
    "        ]].copy()\n",
    "\n",
    "        merged[\"note\"] = \"Salaire estimé (base) – hors bonus/sponsors – source publique\"\n",
    "        all_rows.append(merged)\n",
    "        time.sleep(0.4)\n",
    "\n",
    "    df_final = pd.concat(all_rows, ignore_index=True).sort_values([\"season\", \"driverRank\", \"driverId\"])\n",
    "    out_path = OUT_DIR / \"f1_driver_finance_2021_2025.csv\"\n",
    "    df_final.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ {out_path} créé ({len(df_final)} lignes)\")\n",
    "    return out_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_constructor_finance_csv()\n",
    "    build_driver_finance_filled_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e4271",
   "metadata": {},
   "source": [
    "## Nettoyage des deux csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05de9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> fichiers clean générés\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Constructeurs\n",
    "df_c = pd.read_csv(\"data/f1_constructor_finance_2021_2025.csv\")\n",
    "df_c = df_c.drop(columns=[\"note\"], errors=\"ignore\")\n",
    "df_c.to_csv(\"data/f1_constructor_finance_2021_2025_clean.csv\", index=False)\n",
    "\n",
    "# 2) Pilotes\n",
    "df_d = pd.read_csv(\"data/f1_driver_finance_2021_2025.csv\")\n",
    "\n",
    "# supprimer colonnes de traçabilité (si tu veux)\n",
    "df_d = df_d.drop(columns=[\"note\", \"salarySourceURL\"], errors=\"ignore\")\n",
    "\n",
    "# convertir salaire en entier (en gardant les NaN possibles)\n",
    "df_d[\"estimatedSalaryUSD\"] = pd.to_numeric(df_d[\"estimatedSalaryUSD\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df_d.to_csv(\"data/f1_driver_finance_2021_2025_clean.csv\", index=False)\n",
    "\n",
    "print(\"OK -> fichiers clean générés\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
